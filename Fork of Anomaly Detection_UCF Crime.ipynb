{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: |https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/minibatches/minibatch13.npz\n/kaggle/input/minibatches/minibatch53.npz\n/kaggle/input/minibatches/minibatch2.npz\n/kaggle/input/minibatches/minibatch64.npz\n/kaggle/input/minibatches/minibatch48.npz\n/kaggle/input/minibatches/minibatch9.npz\n/kaggle/input/minibatches/minibatch29.npz\n/kaggle/input/minibatches/minibatch47.npz\n/kaggle/input/minibatches/minibatch60.npz\n/kaggle/input/minibatches/minibatch45.npz\n/kaggle/input/minibatches/minibatch19.npz\n/kaggle/input/minibatches/minibatch11.npz\n/kaggle/input/minibatches/minibatch66.npz\n/kaggle/input/minibatches/minibatch54.npz\n/kaggle/input/minibatches/minibatch15.npz\n/kaggle/input/minibatches/minibatch34.npz\n/kaggle/input/minibatches/minibatch55.npz\n/kaggle/input/minibatches/minibatch32.npz\n/kaggle/input/minibatches/minibatch31.npz\n/kaggle/input/minibatches/minibatch5.npz\n/kaggle/input/minibatches/minibatch58.npz\n/kaggle/input/minibatches/minibatch61.npz\n/kaggle/input/minibatches/minibatch63.npz\n/kaggle/input/minibatches/minibatch3.npz\n/kaggle/input/minibatches/minibatch12.npz\n/kaggle/input/minibatches/minibatch4.npz\n/kaggle/input/minibatches/minibatch25.npz\n/kaggle/input/minibatches/minibatch46.npz\n/kaggle/input/minibatches/minibatch56.npz\n/kaggle/input/minibatches/minibatch27.npz\n/kaggle/input/minibatches/minibatch41.npz\n/kaggle/input/minibatches/minibatch33.npz\n/kaggle/input/minibatches/minibatch0.npz\n/kaggle/input/minibatches/minibatch52.npz\n/kaggle/input/minibatches/minibatch24.npz\n/kaggle/input/minibatches/minibatch43.npz\n/kaggle/input/minibatches/minibatch36.npz\n/kaggle/input/minibatches/minibatch50.npz\n/kaggle/input/minibatches/minibatch67.npz\n/kaggle/input/minibatches/minibatch8.npz\n/kaggle/input/minibatches/minibatch42.npz\n/kaggle/input/minibatches/minibatch28.npz\n/kaggle/input/minibatches/minibatch10.npz\n/kaggle/input/minibatches/minibatch17.npz\n/kaggle/input/minibatches/minibatch59.npz\n/kaggle/input/minibatches/minibatch22.npz\n/kaggle/input/minibatches/minibatch38.npz\n/kaggle/input/minibatches/minibatch6.npz\n/kaggle/input/minibatches/minibatch14.npz\n/kaggle/input/minibatches/minibatch16.npz\n/kaggle/input/minibatches/minibatch18.npz\n/kaggle/input/minibatches/minibatch40.npz\n/kaggle/input/minibatches/minibatch44.npz\n/kaggle/input/minibatches/minibatch35.npz\n/kaggle/input/minibatches/minibatch1.npz\n/kaggle/input/minibatches/minibatch23.npz\n/kaggle/input/minibatches/minibatch51.npz\n/kaggle/input/minibatches/minibatch37.npz\n/kaggle/input/minibatches/minibatch26.npz\n/kaggle/input/minibatches/minibatch62.npz\n/kaggle/input/minibatches/minibatch49.npz\n/kaggle/input/minibatches/minibatch20.npz\n/kaggle/input/minibatches/minibatch21.npz\n/kaggle/input/minibatches/minibatch30.npz\n/kaggle/input/minibatches/minibatch65.npz\n/kaggle/input/minibatches/minibatch7.npz\n/kaggle/input/minibatches/minibatch57.npz\n/kaggle/input/minibatches/minibatch39.npz\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"a=np.arange(68)\nnp.random.shuffle(a)\nprint(a)","execution_count":2,"outputs":[{"output_type":"stream","text":"[26 15 51 20 17 13 59 62  1 24 29 63 52 37 57  0 48 43  9 38  5 11 10 18\n 47 61 28 54 39 66 22 55 40 41 31  7 67 53  8 36 46 35 12 16 44  2 60 50\n 21 14  4 58 19 64 56 45 42 25 23 34 27  6 32 33 65 30 49  3]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#code for shuffling minibatches\ni=0\nj=0\nwhile i<68:\n    Y=[]\n    while j<min(i+10,68):\n        X=np.load(\"/kaggle/input/minibatches/minibatch%d.npz\" % (a[j]))\n        X=X['arr_0']\n        j=j+1\n        Y.append(X)\n    Y1=np.vstack(Y)\n    np.random.shuffle(Y1)\n    Y1=np.split(Y1,Y1.shape[0]/16)\n    for index,arr in enumerate(Y1):\n        np.savez(\"/kaggle/working/shuffled_minibatch%d.npz\"%(i+index),arr)\n    i=j\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/working/shuffled_minibatch19.npz\n/kaggle/working/shuffled_minibatch41.npz\n/kaggle/working/shuffled_minibatch17.npz\n/kaggle/working/shuffled_minibatch18.npz\n/kaggle/working/shuffled_minibatch39.npz\n/kaggle/working/shuffled_minibatch20.npz\n/kaggle/working/shuffled_minibatch7.npz\n/kaggle/working/shuffled_minibatch42.npz\n/kaggle/working/shuffled_minibatch22.npz\n/kaggle/working/shuffled_minibatch63.npz\n/kaggle/working/shuffled_minibatch52.npz\n/kaggle/working/shuffled_minibatch51.npz\n/kaggle/working/shuffled_minibatch34.npz\n/kaggle/working/shuffled_minibatch3.npz\n/kaggle/working/shuffled_minibatch28.npz\n/kaggle/working/shuffled_minibatch14.npz\n/kaggle/working/shuffled_minibatch11.npz\n/kaggle/working/shuffled_minibatch58.npz\n/kaggle/working/shuffled_minibatch36.npz\n/kaggle/working/shuffled_minibatch1.npz\n/kaggle/working/shuffled_minibatch31.npz\n/kaggle/working/shuffled_minibatch8.npz\n/kaggle/working/shuffled_minibatch24.npz\n/kaggle/working/shuffled_minibatch27.npz\n/kaggle/working/shuffled_minibatch5.npz\n/kaggle/working/shuffled_minibatch2.npz\n/kaggle/working/shuffled_minibatch43.npz\n/kaggle/working/shuffled_minibatch59.npz\n/kaggle/working/shuffled_minibatch56.npz\n/kaggle/working/shuffled_minibatch40.npz\n/kaggle/working/shuffled_minibatch65.npz\n/kaggle/working/shuffled_minibatch44.npz\n/kaggle/working/shuffled_minibatch61.npz\n/kaggle/working/shuffled_minibatch67.npz\n/kaggle/working/shuffled_minibatch62.npz\n/kaggle/working/shuffled_minibatch60.npz\n/kaggle/working/shuffled_minibatch13.npz\n/kaggle/working/shuffled_minibatch9.npz\n/kaggle/working/shuffled_minibatch6.npz\n/kaggle/working/shuffled_minibatch26.npz\n/kaggle/working/shuffled_minibatch12.npz\n/kaggle/working/shuffled_minibatch54.npz\n/kaggle/working/shuffled_minibatch30.npz\n/kaggle/working/shuffled_minibatch35.npz\n/kaggle/working/shuffled_minibatch46.npz\n/kaggle/working/shuffled_minibatch47.npz\n/kaggle/working/shuffled_minibatch33.npz\n/kaggle/working/shuffled_minibatch53.npz\n/kaggle/working/shuffled_minibatch55.npz\n/kaggle/working/__notebook_source__.ipynb\n/kaggle/working/shuffled_minibatch0.npz\n/kaggle/working/shuffled_minibatch49.npz\n/kaggle/working/shuffled_minibatch10.npz\n/kaggle/working/shuffled_minibatch50.npz\n/kaggle/working/shuffled_minibatch38.npz\n/kaggle/working/shuffled_minibatch15.npz\n/kaggle/working/shuffled_minibatch29.npz\n/kaggle/working/shuffled_minibatch64.npz\n/kaggle/working/shuffled_minibatch57.npz\n/kaggle/working/shuffled_minibatch16.npz\n/kaggle/working/shuffled_minibatch37.npz\n/kaggle/working/shuffled_minibatch45.npz\n/kaggle/working/shuffled_minibatch4.npz\n/kaggle/working/shuffled_minibatch66.npz\n/kaggle/working/shuffled_minibatch21.npz\n/kaggle/working/shuffled_minibatch32.npz\n/kaggle/working/shuffled_minibatch25.npz\n/kaggle/working/shuffled_minibatch23.npz\n/kaggle/working/shuffled_minibatch48.npz\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import (Input, Activation,\n                                     BatchNormalization, Conv3D,\n                                     LeakyReLU, Conv3DTranspose)\nfrom tensorflow.keras.layers import MaxPool3D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Sequential\nimport tensorflow.keras.backend as K\n\n\ndef AutoEncoderModel():\n    \n    # encoder\n    X_input = Input((16, 128, 128, 3))\n    \n    model = Sequential()\n    model.add(Conv3D(32, 3, padding='same',input_shape=(16,128,128,3)))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid'))\n    \n    # current shape is 8x64x64x32\n    \n    model.add(Conv3D(48, 3, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid'))\n    \n    # current shape is 4x32x32x48\n    \n    model.add(Conv3D(64, 3, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid'))\n    \n    # current shape is 2x16x16x64\n    \n    model.add(Conv3D(64, 3, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='same'))\n    \n    # current shape is 2x16x16x64\n    \n    #####################################\n    # decoder\n\n    model.add(Conv3DTranspose(48, 2, strides=(2, 2, 2), padding='valid'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    \n    # current shape is 4x32x32x48\n    \n    model.add(Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    \n    # current shape is 8x64x64x32\n    \n    model.add(Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='valid'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    \n    # current shape is 16x128x128x32\n    \n    model.add(Conv3D(3, 3, strides=(1, 1, 1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('sigmoid'))\n    \n    # current shape is 16x128x128x3\n\n    # model = Model(inputs=X_input, outputs=X, name='AutoEncoderModel')\n    return model\n\n\ndef custom_loss(new, original):\n    reconstruction_error = K.mean(K.square(new-original))\n    return reconstruction_error\n\nautoEncoderModel = AutoEncoderModel()\nopt = keras.optimizers.Adam(lr=0.001)\nautoEncoderModel.compile(\n    loss=custom_loss, optimizer=opt, metrics=['accuracy'])\nprint(autoEncoderModel.summary())","execution_count":9,"outputs":[{"output_type":"stream","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_23 (Conv3D)           (None, 16, 128, 128, 32)  2624      \n_________________________________________________________________\nbatch_normalization_34 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_21 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nmax_pooling3d_20 (MaxPooling (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_24 (Conv3D)           (None, 8, 64, 64, 48)     41520     \n_________________________________________________________________\nbatch_normalization_35 (Batc (None, 8, 64, 64, 48)     192       \n_________________________________________________________________\nleaky_re_lu_22 (LeakyReLU)   (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nmax_pooling3d_21 (MaxPooling (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_25 (Conv3D)           (None, 4, 32, 32, 64)     83008     \n_________________________________________________________________\nbatch_normalization_36 (Batc (None, 4, 32, 32, 64)     256       \n_________________________________________________________________\nleaky_re_lu_23 (LeakyReLU)   (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nmax_pooling3d_22 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_26 (Conv3D)           (None, 2, 16, 16, 64)     110656    \n_________________________________________________________________\nbatch_normalization_37 (Batc (None, 2, 16, 16, 64)     256       \n_________________________________________________________________\nleaky_re_lu_24 (LeakyReLU)   (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nmax_pooling3d_23 (MaxPooling (None, 2, 16, 16, 64)     0         \n_________________________________________________________________\nconv3d_transpose_9 (Conv3DTr (None, 4, 32, 32, 48)     24624     \n_________________________________________________________________\nbatch_normalization_38 (Batc (None, 4, 32, 32, 48)     192       \n_________________________________________________________________\nleaky_re_lu_25 (LeakyReLU)   (None, 4, 32, 32, 48)     0         \n_________________________________________________________________\nconv3d_transpose_10 (Conv3DT (None, 8, 64, 64, 32)     12320     \n_________________________________________________________________\nbatch_normalization_39 (Batc (None, 8, 64, 64, 32)     128       \n_________________________________________________________________\nleaky_re_lu_26 (LeakyReLU)   (None, 8, 64, 64, 32)     0         \n_________________________________________________________________\nconv3d_transpose_11 (Conv3DT (None, 16, 128, 128, 32)  8224      \n_________________________________________________________________\nbatch_normalization_40 (Batc (None, 16, 128, 128, 32)  128       \n_________________________________________________________________\nleaky_re_lu_27 (LeakyReLU)   (None, 16, 128, 128, 32)  0         \n_________________________________________________________________\nconv3d_27 (Conv3D)           (None, 16, 128, 128, 3)   2595      \n_________________________________________________________________\nbatch_normalization_41 (Batc (None, 16, 128, 128, 3)   12        \n_________________________________________________________________\nactivation_11 (Activation)   (None, 16, 128, 128, 3)   0         \n=================================================================\nTotal params: 286,863\nTrainable params: 286,217\nNon-trainable params: 646\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.layers import Flatten,Dense\nfrom tensorflow.keras import Sequential\ndef create_discriminator_model():\n\n    X_input = Input((16, 128, 128, 3))\n\n    # not sure about the axis in batch norm\n    # do we also add dropout after batchnorm/pooling?\n\n    # Convolutional Layers\n    # changed the no of filters\n    model= Sequential()\n    model.add(Conv3D(filters=48, kernel_size=(2, 2, 2), padding=\"same\",input_shape=(16, 128, 128, 3)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=64, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    model.add(Conv3D(filters=128, kernel_size=(2, 2, 2), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n\n    # to add the 5th layer change the cap to 32 frames\n\n    # X=Conv3D(filters=256,kernel_size=(2,2,2),padding=\"same\")(X)\n    # X=BatchNormalization()(X)\n    # X=Activation('relu')(X)\n    # X=MaxPool3D(pool_size=(2,2,2),strides=(2,2,2))(X)\n\n    # Fully connected layers\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation='relu'))\n    # add batch norm to dense layer\n    model.add(BatchNormalization())\n    # activation done with loss fn\n    # for numerical stability\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model\n\ndiscriminator = create_discriminator_model()\nopt = keras.optimizers.Adam(lr=0.001)\nloss = BinaryCrossentropy()\ndiscriminator.compile(loss=loss,\n                      optimizer=opt,\n                      metrics=['accuracy'])\nprint(discriminator.summary())\n","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_28 (Conv3D)           (None, 16, 128, 128, 48)  1200      \n_________________________________________________________________\nbatch_normalization_42 (Batc (None, 16, 128, 128, 48)  192       \n_________________________________________________________________\nactivation_12 (Activation)   (None, 16, 128, 128, 48)  0         \n_________________________________________________________________\nmax_pooling3d_24 (MaxPooling (None, 8, 64, 64, 48)     0         \n_________________________________________________________________\nconv3d_29 (Conv3D)           (None, 8, 64, 64, 64)     24640     \n_________________________________________________________________\nbatch_normalization_43 (Batc (None, 8, 64, 64, 64)     256       \n_________________________________________________________________\nactivation_13 (Activation)   (None, 8, 64, 64, 64)     0         \n_________________________________________________________________\nmax_pooling3d_25 (MaxPooling (None, 4, 32, 32, 64)     0         \n_________________________________________________________________\nconv3d_30 (Conv3D)           (None, 4, 32, 32, 128)    65664     \n_________________________________________________________________\nbatch_normalization_44 (Batc (None, 4, 32, 32, 128)    512       \n_________________________________________________________________\nactivation_14 (Activation)   (None, 4, 32, 32, 128)    0         \n_________________________________________________________________\nmax_pooling3d_26 (MaxPooling (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nconv3d_31 (Conv3D)           (None, 2, 16, 16, 128)    131200    \n_________________________________________________________________\nbatch_normalization_45 (Batc (None, 2, 16, 16, 128)    512       \n_________________________________________________________________\nactivation_15 (Activation)   (None, 2, 16, 16, 128)    0         \n_________________________________________________________________\nmax_pooling3d_27 (MaxPooling (None, 1, 8, 8, 128)      0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               2097408   \n_________________________________________________________________\nbatch_normalization_46 (Batc (None, 256)               1024      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 2,322,865\nTrainable params: 2,321,617\nNon-trainable params: 1,248\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nclass GAN():\n    def __init__(self):\n        self.image_shape=(16,128,128,3)\n        learning_rate=0.03\n        opt=keras.optimizers.Adam(lr=learning_rate)\n        opt1=keras.optimizers.Adam(lr=learning_rate)\n        opt_slow=keras.optimizers.Adam(lr=10*learning_rate)\n        #Build and compile the discriminator\n        self.discriminator=create_discriminator_model()\n        self.discriminator.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n        #Build and compile the generator\n        self.generator=AutoEncoderModel()\n        self.generator.compile(loss='mse',optimizer=opt_slow)\n\n        #the generator takes a video as input and generates a modified video\n        z = Input(shape=(self.image_shape))\n        img = self.generator(z)\n        self.discriminator.trainable = False\n        validity = self.discriminator(img)\n        self.combined = Model(z, validity)\n        self.combined.compile(loss='binary_crossentropy', optimizer=opt1,metrics=['accuracy'])\n\n    def train(self,epochs,mini_batch_size):\n        #this function will need to be added later\n        for epoch in range(epochs):\n            d_loss_sum=np.zeros(2)\n            reconstruct_error_sum=0\n            g_loss_sum=np.zeros(2)\n            for i in range(68):\n                # ---------------------\n                #  Train Discriminator\n                # ---------------------\n                minibatch=np.load('/kaggle/working/shuffled_minibatch%d.npz' %(i))\n                minibatch=minibatch['arr_0']\n                minibatch=K.cast(minibatch,'float32')\n                #normalize inputs\n                minibatch/=255\n                gen_vids=self.generator.predict(minibatch)\n                #might have to combine these to improve batch norm\n                d_loss_real=self.discriminator.train_on_batch(minibatch,np.ones((mini_batch_size,1)))\n                d_loss_fake=self.discriminator.train_on_batch(gen_vids,np.zeros((mini_batch_size,1)))\n                d_loss=0.5*np.add(d_loss_real,d_loss_fake)\n                # ---------------------\n                #  Train Generator\n                # ---------------------\n                # The generator wants the discriminator to label the generated samples as valid (ones)\n                valid_y = np.array([1] * mini_batch_size)\n                # Train the generator\n                g_loss = self.combined.train_on_batch(minibatch,valid_y)\n                reconstruct_error=self.generator.train_on_batch(minibatch,minibatch)\n                d_loss_sum+=d_loss\n                g_loss_sum+=g_loss\n                reconstruct_error_sum+=reconstruct_error\n            g_loss=g_loss_sum/68\n            d_loss=d_loss_sum/68\n            reconstruct_error=reconstruct_error_sum/68\n            # Plot the progress\n            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, accuracy %.2f%% from which %f is combined loss and %f is reconstruction loss]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0]+reconstruct_error,g_loss[1]*100,g_loss[0],reconstruct_error))\n        \ngan = GAN()\nprint(gan.combined.summary())\n\n# print(gan.discriminator.summary())\n# print(gan.generator.summary())\n","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_12 (InputLayer)        [(None, 16, 128, 128, 3)] 0         \n_________________________________________________________________\nsequential_8 (Sequential)    (None, 16, 128, 128, 3)   286863    \n_________________________________________________________________\nsequential_7 (Sequential)    (None, 1)                 2322865   \n=================================================================\nTotal params: 2,609,728\nTrainable params: 286,217\nNon-trainable params: 2,323,511\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan.train(100,16)","execution_count":12,"outputs":[{"output_type":"stream","text":"0 [D loss: 0.729393, acc.: 37.41%] [G loss: 93.707233, accuracy 0.95% from which 93.672831 is combined loss and 0.034402 is reconstruction loss]\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-02e17e84421e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-c0bccab5d9d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, mini_batch_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mvalid_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# Train the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mreconstruct_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0md_loss_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           standalone=True)\n\u001b[0m\u001b[1;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m   1080\u001b[0m                  outputs['metrics'])\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3321\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3322\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3323\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3324\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 821\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    822\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m    141\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         tld.op_callbacks, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}